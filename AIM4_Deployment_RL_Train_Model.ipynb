{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Frozen Lake (Q-Learning)\n",
        "\n",
        "Contoh Deloyment untuk Domain Reinforcement Learning (RL) <br>\n",
        "Orbit Future Academy - AI Mastery - KM Batch 3 <br>\n",
        "Tim Deployment dan Tim RL <br>\n",
        "2022"
      ],
      "metadata": {
        "id": "3KHeFKkkPkDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules dan Packages"
      ],
      "metadata": {
        "id": "ifw95G4rPnii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haYB0uN0O5VM",
        "outputId": "5055d25e-912f-4604-e26b-dedfcadde5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym==0.17.3\n",
            "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.22.4)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0 (from gym==0.17.3)\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0 (from gym==0.17.3)\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (0.18.3)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654650 sha256=1dfc463b77cee8d87ba9ea65555d3964e739a6dd703d0df06d9f1f623db2c11c\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/4b/74/fcfc8238472c34d7f96508a63c962ff3ac9485a9a4137afd4e\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, cloudpickle, gym\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed cloudpickle-1.6.0 gym-0.17.3 pyglet-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.17.3 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import pickle"
      ],
      "metadata": {
        "id": "TK1YKkXKPk0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Environment"
      ],
      "metadata": {
        "id": "aW35UbipPt8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Peta (ada 5 peta)\n",
        "peta = [\n",
        "    ['SFFF','FHFH','FFFH','HFFG'],\n",
        "    ['SFFF','FFHF','HFFF','HFFG'],\n",
        "    ['SHFF','FHFH','FFFH','HHFG'],\n",
        "    ['SFFF','HHFF','FFFF','HFFG'],\n",
        "    ['SFFH','FFFH','HFFH','HHFG']\n",
        "]"
      ],
      "metadata": {
        "id": "AdoVbfurPuZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Environment\n",
        "env = gym.make(\"FrozenLake-v0\",is_slippery=False, desc=peta[0])"
      ],
      "metadata": {
        "id": "JB8ZcmImPvUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_observations = env.observation_space.n\n",
        "n_actions      = env.action_space.n\n",
        "\n",
        "print('Banyak State  : ' + str(n_observations))\n",
        "print('Banyak Action : ' + str(n_actions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8WXRzPYPxss",
        "outputId": "a30a749a-7d40-43e0-a576-5eb1c3e191c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banyak State  : 16\n",
            "Banyak Action : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACTION = [\"KIRI\",\"BAWAH\",\"KANAN\",\"ATAS\"]"
      ],
      "metadata": {
        "id": "H9dkIRTPP1An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmAkvVIeP2S1",
        "outputId": "9269fdcd-ca82-4790-e2bc-98f907d62242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 1 (ke Kanan)\n",
        "new_state, reward, done, info = env.step(2)\n",
        "\n",
        "print('New State : ' + str(new_state))\n",
        "print('Reward    : ' + str(reward))\n",
        "print('Done      : ' + str(done))\n",
        "\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVLve3CWP6iP",
        "outputId": "d544611a-3809-4034-8498-a4bb3ed75c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 1\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 2 (ke Kanan)\n",
        "new_state, reward, done, info = env.step(2)\n",
        "\n",
        "print('New State : ' + str(new_state))\n",
        "print('Reward    : ' + str(reward))\n",
        "print('Done      : ' + str(done))\n",
        "\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTkDEAFjP-8d",
        "outputId": "59dbba99-3852-4c65-bf76-ec1811cb7d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 2\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3 (ke Bawah)\n",
        "new_state, reward, done, info = env.step(1)\n",
        "\n",
        "print('New State : ' + str(new_state))\n",
        "print('Reward    : ' + str(reward))\n",
        "print('Done      : ' + str(done))\n",
        "\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHneMCsmQA7Q",
        "outputId": "1493b364-d5f3-46c3-9d1b-d39120e14a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 6\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FH\u001b[41mF\u001b[0mH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 4 (ke Bawah)\n",
        "new_state, reward, done, info = env.step(1)\n",
        "\n",
        "print('New State : ' + str(new_state))\n",
        "print('Reward    : ' + str(reward))\n",
        "print('Done      : ' + str(done))\n",
        "\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5KSDRqEQCRt",
        "outputId": "94a0bd70-76ef-46db-e0a0-90b40595d9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 10\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 5 (ke Bawah)\n",
        "new_state, reward, done, info = env.step(1)\n",
        "\n",
        "print('New State : ' + str(new_state))\n",
        "print('Reward    : ' + str(reward))\n",
        "print('Done      : ' + str(done))\n",
        "\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR6eQL84QDje",
        "outputId": "a2da543b-92b4-430e-c388-c8dd60fb9ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 14\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 6 (ke Kanan)\n",
        "new_state, reward, done, info = env.step(2)\n",
        "\n",
        "print('New State : ' + str(new_state))\n",
        "print('Reward    : ' + str(reward))\n",
        "print('Done      : ' + str(done))\n",
        "\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm-iPy_JQE2x",
        "outputId": "62b8f35e-b9ff-4a42-ead0-0d87746ab18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 15\n",
            "Reward    : 1.0\n",
            "Done      : True\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model/Agent"
      ],
      "metadata": {
        "id": "SRjVKDqTQG9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_agent(env):\n",
        "    # banyak episode yang akan dijalankan\n",
        "    n_episodes = 10000\n",
        "\n",
        "    # iterasi maksimum per episode\n",
        "    max_iter_episode = 100\n",
        "\n",
        "    # inisialisasi probabilitas eksplorasi\n",
        "    exploration_proba = 1\n",
        "\n",
        "    # penurunan eksplorasi secara eksponensial\n",
        "    exploration_decreasing_decay = 0.001\n",
        "\n",
        "    # probabilitas eksplorasi minimum\n",
        "    min_exploration_proba = 0.01\n",
        "\n",
        "    # faktor diskon\n",
        "    gamma = 0.99\n",
        "\n",
        "    # learning rate\n",
        "    lr = 0.1\n",
        "    \n",
        "    # Inisialisasi Q-table \n",
        "    Q_table = np.zeros((n_observations,n_actions))\n",
        "    \n",
        "    total_rewards_episode = list()\n",
        "    rewards_per_episode=[]\n",
        "    \n",
        "    for e in range(n_episodes):\n",
        "        current_state = env.reset()\n",
        "        done = False\n",
        "        total_episode_reward = 0\n",
        "\n",
        "        for i in range(max_iter_episode):      \n",
        "            if np.random.uniform(0,1) < exploration_proba:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(Q_table[current_state,:])\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            Q_table[current_state, action] = (1-lr) * Q_table[current_state, action] +lr*(reward + gamma*max(Q_table[next_state,:]))\n",
        "            total_episode_reward = total_episode_reward + reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            current_state = next_state\n",
        "\n",
        "        exploration_proba = max(min_exploration_proba, np.exp(-exploration_decreasing_decay*e))\n",
        "        rewards_per_episode.append(total_episode_reward)\n",
        "    \n",
        "    print(\"Rata-Rata Reward per 1000 Episode\")\n",
        "    for i in range(10):\n",
        "        print((i+1)*1000, \" : Rata-Rata Reward: \", np.mean(rewards_per_episode[1000*i:1000*(i+1)])) \n",
        "    \n",
        "    return Q_table"
      ],
      "metadata": {
        "id": "uMKulS39QHaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q_table_all = []\n",
        "\n",
        "for peta_env in peta:\n",
        "    # Load Environment untuk setiap peta\n",
        "    env = gym.make(\"FrozenLake-v0\",is_slippery=False, desc=peta_env)\n",
        "    env.reset()\n",
        "    \n",
        "    print('Peta : ')\n",
        "    print(peta_env)\n",
        "    print()\n",
        "    \n",
        "    # Melatih Agent\n",
        "    Q_table = train_agent(env)\n",
        "    \n",
        "    # Menyimpan Q_table\n",
        "    Q_table_all.append(Q_table)\n",
        "    \n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT9K1SYWQJnI",
        "outputId": "64a97da3-91dd-4aed-b61d-de9b3f8df50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peta : \n",
            "['SFFF', 'FHFH', 'FFFH', 'HFFG']\n",
            "\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.255\n",
            "2000  : Rata-Rata Reward:  0.751\n",
            "3000  : Rata-Rata Reward:  0.925\n",
            "4000  : Rata-Rata Reward:  0.974\n",
            "5000  : Rata-Rata Reward:  0.988\n",
            "6000  : Rata-Rata Reward:  0.989\n",
            "7000  : Rata-Rata Reward:  0.988\n",
            "8000  : Rata-Rata Reward:  0.989\n",
            "9000  : Rata-Rata Reward:  0.987\n",
            "10000  : Rata-Rata Reward:  0.994\n",
            "\n",
            "Peta : \n",
            "['SFFF', 'FFHF', 'HFFF', 'HFFG']\n",
            "\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.427\n",
            "2000  : Rata-Rata Reward:  0.873\n",
            "3000  : Rata-Rata Reward:  0.96\n",
            "4000  : Rata-Rata Reward:  0.978\n",
            "5000  : Rata-Rata Reward:  0.992\n",
            "6000  : Rata-Rata Reward:  0.994\n",
            "7000  : Rata-Rata Reward:  0.997\n",
            "8000  : Rata-Rata Reward:  0.994\n",
            "9000  : Rata-Rata Reward:  0.995\n",
            "10000  : Rata-Rata Reward:  0.991\n",
            "\n",
            "Peta : \n",
            "['SHFF', 'FHFH', 'FFFH', 'HHFG']\n",
            "\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.003\n",
            "2000  : Rata-Rata Reward:  0.57\n",
            "3000  : Rata-Rata Reward:  0.864\n",
            "4000  : Rata-Rata Reward:  0.941\n",
            "5000  : Rata-Rata Reward:  0.977\n",
            "6000  : Rata-Rata Reward:  0.986\n",
            "7000  : Rata-Rata Reward:  0.983\n",
            "8000  : Rata-Rata Reward:  0.972\n",
            "9000  : Rata-Rata Reward:  0.983\n",
            "10000  : Rata-Rata Reward:  0.981\n",
            "\n",
            "Peta : \n",
            "['SFFF', 'HHFF', 'FFFF', 'HFFG']\n",
            "\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.433\n",
            "2000  : Rata-Rata Reward:  0.87\n",
            "3000  : Rata-Rata Reward:  0.955\n",
            "4000  : Rata-Rata Reward:  0.98\n",
            "5000  : Rata-Rata Reward:  0.995\n",
            "6000  : Rata-Rata Reward:  0.994\n",
            "7000  : Rata-Rata Reward:  0.996\n",
            "8000  : Rata-Rata Reward:  0.994\n",
            "9000  : Rata-Rata Reward:  0.996\n",
            "10000  : Rata-Rata Reward:  0.997\n",
            "\n",
            "Peta : \n",
            "['SFFH', 'FFFH', 'HFFH', 'HHFG']\n",
            "\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.264\n",
            "2000  : Rata-Rata Reward:  0.71\n",
            "3000  : Rata-Rata Reward:  0.902\n",
            "4000  : Rata-Rata Reward:  0.976\n",
            "5000  : Rata-Rata Reward:  0.985\n",
            "6000  : Rata-Rata Reward:  0.993\n",
            "7000  : Rata-Rata Reward:  0.988\n",
            "8000  : Rata-Rata Reward:  0.986\n",
            "9000  : Rata-Rata Reward:  0.993\n",
            "10000  : Rata-Rata Reward:  0.991\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memainkan Agent yang Telah Dilatih"
      ],
      "metadata": {
        "id": "MCc-2bZ-QNNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_peta = 0 # silahkan pilih peta\n",
        "\n",
        "env = gym.make(\"FrozenLake-v0\",is_slippery=False, desc=peta[index_peta])\n",
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYCGjTVcQNwy",
        "outputId": "65f72398-4a92-4675-9202-f45fcaedc6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for langkah in range(1,7):\n",
        "    if langkah == 1:\n",
        "        best_action = np.argmax(Q_table_all[index_peta][0])\n",
        "    else:\n",
        "        best_action = np.argmax(Q_table_all[index_peta][current_state])\n",
        "        \n",
        "    new_state, reward, done, info = env.step(best_action)\n",
        "\n",
        "    print('Langkah ke  : ' + str(langkah))\n",
        "    print('Best Action : ' + ACTION[best_action])\n",
        "    print('New State   : ' + str(new_state))\n",
        "    print('Reward      : ' + str(reward))\n",
        "    print('Done        : ' + str(done))\n",
        "    print()\n",
        "\n",
        "    env.render()\n",
        "    \n",
        "    current_state = new_state\n",
        "    \n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn_SWx9CQTYb",
        "outputId": "66015043-f9de-4ca6-c800-761600b349e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langkah ke  : 1\n",
            "Best Action : KANAN\n",
            "New State   : 1\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "Langkah ke  : 2\n",
            "Best Action : KANAN\n",
            "New State   : 2\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "Langkah ke  : 3\n",
            "Best Action : BAWAH\n",
            "New State   : 6\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "\n",
            "  (Down)\n",
            "SFFF\n",
            "FH\u001b[41mF\u001b[0mH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "Langkah ke  : 4\n",
            "Best Action : BAWAH\n",
            "New State   : 10\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "\n",
            "Langkah ke  : 5\n",
            "Best Action : BAWAH\n",
            "New State   : 14\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "\n",
            "Langkah ke  : 6\n",
            "Best Action : KANAN\n",
            "New State   : 15\n",
            "Reward      : 1.0\n",
            "Done        : True\n",
            "\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Periksa Apakah Agent Dapat Menyelesaikan Semua Peta"
      ],
      "metadata": {
        "id": "7SwD0ohLQVJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for peta_env in peta:\n",
        "    print(\"Peta   : \" + str(peta_env))\n",
        "    \n",
        "    env = gym.make(\"FrozenLake-v0\",is_slippery=False, desc=peta_env)\n",
        "    env.reset()\n",
        "    \n",
        "    for langkah in range(1,7):\n",
        "        if langkah == 1:\n",
        "            best_action = np.argmax(Q_table_all[index_peta][0])\n",
        "        else:\n",
        "            best_action = np.argmax(Q_table_all[index_peta][current_state])\n",
        "\n",
        "        new_state, reward, done, info = env.step(best_action)\n",
        "\n",
        "        current_state = new_state\n",
        "\n",
        "    if done == True:\n",
        "        print(\"Status : Agent dapat menyelesaikan peta ini\")\n",
        "    else:\n",
        "        print(\"Status : Agent tidak dapat menyelesaikan peta ini\")\n",
        "        \n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQh0oFc3QVqX",
        "outputId": "0f51103a-8227-43c1-ae68-70ebab597c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peta   : ['SFFF', 'FHFH', 'FFFH', 'HFFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SFFF', 'FFHF', 'HFFF', 'HFFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SHFF', 'FHFH', 'FFFH', 'HHFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SFFF', 'HHFF', 'FFFF', 'HFFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SFFH', 'FFFH', 'HFFH', 'HHFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menyimpan Model"
      ],
      "metadata": {
        "id": "FyEx0-qeQX63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(Q_table_all, open('Q_table_Frozen_Lake.model', 'wb'))"
      ],
      "metadata": {
        "id": "xnRk7UxhQYVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00kcPfVUQdRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}